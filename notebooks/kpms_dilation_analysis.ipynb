{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse results of moseq model on Mo's dataset under dilation of given mice to see the relationship between gross morphological variable and syllables\n",
    "\n",
    "Relies on the moseq syllables and computed in `kpms_under_dilation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3 --print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kpsn_moseq_explore.lib.kpms_custom_io as cio\n",
    "from kpsn_moseq_explore import viz\n",
    "from kpsn_moseq_explore import lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keypoint_moseq as kpms\n",
    "\n",
    "root_dir = '/home/kaf200/datta/kai/mph/moseq-explore'\n",
    "project_dir = f'{root_dir}/kpms_projects/modata'\n",
    "data_dir = f'{root_dir}/recordings/modata'\n",
    "model_name = 'allsubj_continued'\n",
    "results_dir = f'{root_dir}/kpms_results/modata/{model_name}'\n",
    "config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = jl.load(f'{results_dir}/pop-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions and scale factors run through kpms\n",
    "sessions = ['3wk_m0']\n",
    "scale_factors = [0.75, 1.25, 1.5]\n",
    "\n",
    "scaled_results = lambda session, scale_factor: jl.load(\n",
    "    f'{results_dir}/dilation/{session}-f{scale_factor}-results.p')[session]\n",
    "\n",
    "# syllables used in the population and/or by a scaled session\n",
    "sylls = np.unique(np.concatenate(\n",
    "    [np.unique(r['syllable'])\n",
    "     for r in base_results.values()] +\n",
    "    [np.unique(scaled_results(session, scale_factor)['syllable'])\n",
    "     for session in sessions for scale_factor in scale_factors]\n",
    "    ))\n",
    "\n",
    "# count percent of frames in which a syllable is used\n",
    "base_frame_pcts = {\n",
    "    session: np.array([\n",
    "        (base_results[session]['syllable'] == s).mean() for s in sylls])\n",
    "    for session in base_results}\n",
    "\n",
    "scaled_frame_pcts = {\n",
    "    session: {scale_factor:\n",
    "            np.array([\n",
    "                (scaled_results(session, scale_factor)['syllable'] == s\n",
    "                 ).mean() for s in sylls])\n",
    "        for scale_factor in scale_factors}\n",
    "    for session in sessions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there syllables used in the scaled sessions not used in the original?\n",
    "# and vice versa?\n",
    "# - example of very obvious deviation\n",
    "# - (also can we look at log usages)\n",
    "\n",
    "for session in sessions:\n",
    "    for scale_factor in scale_factors:\n",
    "        introduced_sylls = (\n",
    "           (scaled_frame_pcts[session][scale_factor] != 0) &\n",
    "           (base_frame_pcts[session] == 0))\n",
    "\n",
    "        dropped_sylls = (\n",
    "           (scaled_frame_pcts[session][scale_factor] != 0) &\n",
    "           (base_frame_pcts[session] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 29, 29, ..., 42, 42, 42])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = '3wk_m0'\n",
    "\n",
    "fig, ax = plt.subplots(1, len(scale_factors), figsize = (len(scale_factors) * 3, 3))\n",
    "\n",
    "for i_factor, scale_factor in scale_factors:\n",
    "    scale_results = jl.load(f'{results_dir}/dilation/{session}-f{scale_factor}-results.p')\n",
    "    scale_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['3wk_m0'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = 0.75; session = '3wk_m0'\n",
    "jl.load(f'{results_dir}/dilation/{session}-f{scale_factor}-results.p').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mph_kpms",
   "language": "python",
   "name": "mph_kpms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
